{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 瑕疵檢測簡介\n",
    "* 發展智慧工廠已經成為全球產業的趨勢，但對產業來說無論工廠如何演進，品質和良率都是無法避免且必須解決的問題\n",
    "* 對應產業的需要，機器視覺常被使用於工業檢測、尺寸量測、自動化導引等用途\n",
    "* 近年來隨著深度學習技術的發展，AI技術紛紛導入產業應用，AI瑕疵檢測使用深度學習技術將成為下一波發展重點與智慧製造商機所在\n",
    "* 深度學習技術改善傳統光學檢測（AOI）難以檢測的不規律瑕疵及特徵，有效解決刮痕、污垢、裂縫、缺件、變型和歪曲的字體以及無固定顏色、大小、形狀等難以依賴光學架構與影像處理來突顯及分離之瑕疵和特徵\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/傳統AOI流程.jpg\" alt=\"architecture\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 現行AOI如何減少人力與提高準確率\n",
    "\n",
    "* 原本全人工檢查\n",
    "* 自動化檢查配合人工複檢\n",
    "* 新創應用\n",
    "\n",
    "<img src=\"img/AOI如何減少人力提高準確率.jpg\" width=\"90%\" height=\"90%\" alt=\"architecture\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以深度學習加值AOI應用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝與導入套件\n",
    "\n",
    "note:只有初始建立容器時由於附加外掛工具，才需要重啟jupyter: 1.按Quit鍵結束jp nb, 2.ssh登入後重啟 $jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:34:16.401043Z",
     "start_time": "2019-12-12T03:34:07.285549Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install matplotlib\n",
    "!sudo pip install Pillow\n",
    "!sudo pip install keras_tqdm\n",
    "!sudo pip install sklearn\n",
    "!sudo pip install jupyter_contrib_nbextensions \n",
    "!sudo jupyter contrib nbextension install\n",
    "!pip install autopep8\n",
    "!sudo pip install -U jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:35:32.108947Z",
     "start_time": "2019-12-19T06:35:28.966006Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "from PIL import Image\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython import display\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料集(Dataset)\n",
    "## 資料收集、清洗、爬梳\n",
    "### (NEU surface defect database)\n",
    "\n",
    "\n",
    "<img src=\"img/imageflow-gr1.jpg\"  width=\"550%\" height=\"250%\" alt=\"outline \" align=center />\n",
    "\n",
    "\n",
    "* 資料庫包含1,800個灰階影像\n",
    "* 每張影像的原始解析度為200×200像素\n",
    "* 六種不同類型的表面缺陷，每個類別各有300張影像\n",
    "* 需要把正常影像當作一類嗎？\n",
    "* **<font color = red> 工人智慧</font>**\n",
    "\n",
    "\n",
    "## 資料標註(Annotation)\n",
    "\n",
    "\n",
    "<img src=\"img/dataset_flow_01.jpg\" width=\"550%\" height=\"250%\" alt=\"outline \" align=center />\n",
    "\n",
    "#### 資料集標註成六種類別：\n",
    " rolled-in scale (RS), patches (Pa), crazing (Cr), pitted surface (PS), inclusion (In) and scratches (Sc)\n",
    " \n",
    " 軋入鏽皮（RS）     ，斑塊（Pa） ，裂紋（Cr），凹痕表面（ PS）  ，雜質（In）     和    划痕（Sc）\n",
    "\n",
    "<img src=\"img/6classesSample.jpg\" width=\"550%\" height=\"250%\" alt=\"outline \" align=center />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料清洗(簡)\n",
    "### note:訓練集的製備是模型訓練效能最重要的步驟之一\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T08:04:50.838489Z",
     "start_time": "2019-12-19T08:04:40.550007Z"
    }
   },
   "source": [
    "### 下載dataset\n",
    "\n",
    "Terminal\n",
    "\n",
    "`$sh getdata_NEU.sh`\n",
    "\n",
    "or Jupyter\n",
    "\n",
    "`!rm -rf getdata_NEU`;\n",
    "`!sh getdata_NEU.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:35:58.067722Z",
     "start_time": "2019-12-19T06:35:39.407707Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# 準備Training set\n",
    "classes = ['In', 'Cr', 'Pa', 'PS', 'RS', 'Sc']\n",
    "class_name = ['Inclusion', 'Crazing', 'Patches',\n",
    "              'Pitted surface', 'Rolled-in scale', 'Scratches']\n",
    "\n",
    "dataset_path = './data_NEU/'\n",
    "data_path = []\n",
    "dataset_images = []\n",
    "dataset_labels = []\n",
    "train_images = []\n",
    "train_labels = []\n",
    "val_images = []\n",
    "val_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# train val test 比例\n",
    "dataset_proport = np.array([60, 20, 20])\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for f in files:\n",
    "        data_path.append(f)\n",
    "        \n",
    "dataset_proport = (dataset_proport/100*len(data_path)).astype(int)\n",
    "\n",
    "random.shuffle(data_path)\n",
    "for path in data_path:\n",
    "    onehot = [0, 0, 0, 0, 0, 0]\n",
    "    image = Image.open(dataset_path+path)\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((224, 224), Image.BILINEAR)\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    dataset_images.append(image)\n",
    "    onehot[classes.index(path.split('.')[0].split('_')[0])] += 1\n",
    "    dataset_labels.append(onehot)\n",
    "\n",
    "train_images = np.asarray(dataset_images[:dataset_proport[0]])\n",
    "train_labels = np.asarray(dataset_labels[:dataset_proport[0]])\n",
    "val_images = np.asarray(dataset_images[dataset_proport[0]:dataset_proport[0]+dataset_proport[1]])\n",
    "val_labels = np.asarray(dataset_labels[dataset_proport[0]:dataset_proport[0]+dataset_proport[1]])\n",
    "test_images = np.asarray(dataset_images[dataset_proport[0]+dataset_proport[1]:])\n",
    "test_labels = np.asarray(dataset_labels[dataset_proport[0]+dataset_proport[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:35:58.627412Z",
     "start_time": "2019-12-19T06:35:58.479435Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls ./data_NEU | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:35:59.192168Z",
     "start_time": "2019-12-19T06:35:59.040115Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "!ls ./data_NEU/Cr*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note:通常由該領域有經驗者確認資料正確性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:36:16.951562Z",
     "start_time": "2019-12-19T06:36:14.305587Z"
    }
   },
   "outputs": [],
   "source": [
    "# 觀察資料/決定類別/清洗/調整\n",
    "plt.figure(figsize=(25, 25))\n",
    "k = 1\n",
    "for i in range(6):\n",
    "    for j in range(10):\n",
    "        plt.subplot(6, 10, k)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(dataset_images[i*300+j], cmap=plt.cm.binary)\n",
    "        # The CIFAR labels happen to be arrays,\n",
    "        # which is why you need the extra index\n",
    "        plt.xlabel(class_name[np.argmax(dataset_labels[i*300+j], axis=-1)], fontsize=14)\n",
    "        k += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇模型\n",
    "\n",
    "* 使用場域\n",
    "* 準確率\n",
    "* 辨識速度\n",
    "\n",
    "<img src=\"img/各種模型效能比較.jpg\" alt=\"architecture\" align=center />\n",
    "\n",
    "### Demo使用Inceptionv3 架構\n",
    "\n",
    "* Inception(GoogLeNet)在2014年ILSVRC的分類比賽中拿到了第一名，GoogLeNet使用Inception的結構來取代了原本的卷積層，不同於VGG或是AlexNet加深網路的概念，而他的訓練參數也比AlexNet少上好幾倍，準確率相對更好。\n",
    "* 目前使用Inception v3版本作為範例，是廣泛使用的圖片辨識模型，於 ImageNet 資料集達到 78.1% 以上的準確率。這個模型是眾研究人員長年投入大量心力的心血結晶，並以 Szegedy 等人合著的原始論文《Rethinking the Inception Architecture for Computer Vision》為依據\n",
    "* 模型本身是由對稱及非對稱的建構基礎組成，其中包括convolutions, average pooling, max pooling, concats, dropouts, fully connected層。Batchnorm 在整個模型中廣泛使用，並套用至啟動輸入，損失值則透過 Softmax 計算。\n",
    "* 整個網路架構如下所示，其深度為42層\n",
    "* 參數總計: 22,854,950\n",
    "\n",
    "<img src=\"img/Inceptionv3.png\" alt=\"architecture\" align=center />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. 論文來源:https://arxiv.org/abs/1512.00567 \n",
    "2. 圖片來源:https://cloud.google.com/tpu/docs/inception-v3-advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:36:27.189390Z",
     "start_time": "2019-12-19T06:36:22.728924Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for architecture\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 6\n",
    "# conv_size = 32\n",
    "\n",
    "# parameters for training\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# load MobileNet from Keras\n",
    "InceptionV3_model = InceptionV3(\n",
    "    include_top=False, weights=None, input_shape=input_shape)\n",
    "# add custom Layers\n",
    "x = InceptionV3_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "Custom_Output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# define the input and output of the model\n",
    "model = Model(inputs=InceptionV3_model.input, outputs=Custom_Output)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:36:31.879846Z",
     "start_time": "2019-12-19T06:36:31.793465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練模型\n",
    "\n",
    "相關參數設定：\n",
    "* batch_size=256\n",
    "* epochs=100\n",
    "* learning_rate=0.001\n",
    "\n",
    "### 訓練集分配\n",
    "#### train/validation/test (6:2:2)\n",
    "\n",
    "- train:用作訓練模型\n",
    "- validation:更新模型參數\n",
    "- test:最終模型效能測試\n",
    "\n",
    "<img src=\"img/dataset.JPG\" width=\"75%\" height=\"75%\" align=\"left\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:36:36.478247Z",
     "start_time": "2019-12-19T06:36:36.296975Z"
    }
   },
   "outputs": [],
   "source": [
    "# clear temp\n",
    "!rm -rf logs ;mkdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:42:09.448072Z",
     "start_time": "2019-12-19T06:36:46.427573Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "time_now = time.time()\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(verbose=0),\n",
    "    TQDMNotebookCallback(leave_inner=False, leave_outer=True),\n",
    "    TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    callbacks=callbacks)\n",
    "gup_time = time.time()-time_now\n",
    "print(\"總共耗時:\"+format(gup_time, '.2f')+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:42:28.000613Z",
     "start_time": "2019-12-19T06:42:27.805274Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard in notebook\n",
    "\n",
    "note:目前容器預設是關閉tb服務，需要手動啟用。\n",
    "1. 容器管理頁面，開啟關聯port。例如：目標埠: 5000 對外埠: 54558\n",
    "2. 至terminals中 cd ~/your_Lab_NEU/\n",
    "3. 啟用TB: $tensorboard --logdir logs --port 5000 #目標埠: 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:53:34.617044Z",
     "start_time": "2019-12-19T06:53:30.950486Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# 對外埠: 54558\n",
    "%tensorboard --logdir=\"logs\" --port=54558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:54:28.122894Z",
     "start_time": "2019-12-19T06:54:13.449044Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for index in range(0, 1800, 100):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    predicted_batch = model.predict(\n",
    "        np.array([dataset_images[index]], dtype=float))\n",
    "    predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "    title = 'True Class: '+str(class_name[np.argmax(dataset_labels[index], axis=-1)]) + \\\n",
    "        '\\n Predicted Class: '+str(class_name[int(predicted_id)])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(dataset_images[index], cmap=plt.cm.binary)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "    time.sleep(0.3)\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型效能評估\n",
    "* confusion_matrix\n",
    "\n",
    "訓練好的模型使用測試集(Test set)評估效能\n",
    "\n",
    "* 從資料收集到模型評估是遞迴流程，彼此間充滿不斷地修正與更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:54:40.023280Z",
     "start_time": "2019-12-19T06:54:37.658277Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inference all 'test set'\n",
    "print(\"Test images =\",len(test_images))\n",
    "predicted_labels = []\n",
    "predicted_batch = model.predict(np.array(test_images, dtype=float), batch_size=256)\n",
    "predicted_labels = np.argmax(predicted_batch, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:54:46.051629Z",
     "start_time": "2019-12-19T06:54:46.043519Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    plt.xticks(tick_marks, classes, fontsize=16)\n",
    "    plt.yticks(tick_marks, classes, fontsize=16)\n",
    "    plt.axis([-0.5, 5.5, 5.5, -0.5])\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=16)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:54:52.132865Z",
     "start_time": "2019-12-19T06:54:52.131046Z"
    }
   },
   "outputs": [],
   "source": [
    "#!sudo pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T06:55:24.948527Z",
     "start_time": "2019-12-19T06:55:24.521641Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "cnf_matrix = confusion_matrix(np.argmax(test_labels, axis=-1), predicted_labels)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes,\n",
    "                      normalize=True, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWCC服務與效能實例\n",
    "\n",
    "https://www.twcc.ai/\n",
    "\n",
    "### 三大服務領域\n",
    "<img src=\"img/TWCC三大服務類別.jpg\" width=\"95%\" height=\"95%\" align=left />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 協助企業成效\n",
    "\n",
    "* 減少90%訓練時間：博遠智能\n",
    "* 提升效能498倍：雲像科技\n",
    "* 改善23%的準確度：雲守護安控\n",
    "\n",
    "<img src=\"img/TWCC Introduction (NCHC)_v2_企業案例實測效能.jpg\" width=\"95%\" height=\"95%\" align=left />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 產業訓練服務\n",
    "\n",
    "國網中心的AI 產業訓練，是以企業為服務對象，藉由需求訪談了解企業實際的AI策略和應用需求，設計規劃系列AI課程內容，並透過提供個別企業的AI相關課程教學來提升人才技術能力，協助企業將AI技術於場域內落地實現，創造企業的新價值，也藉此達成產業升級、產業AI化的國家級目標。\n",
    "\n",
    "https://www.nchc.org.tw/Page?itemid=13&mid=20\n",
    "\n",
    "\n",
    "<img src=\"img/AI 產業訓練.jpg\" width=\"95%\" height=\"95%\" align=left />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "601px",
    "left": "997px",
    "right": "20px",
    "top": "58px",
    "width": "391px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
